{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L2xAshEHJ10k"
   },
   "source": [
    "Document for Model training\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V4AfHQ06Mvog"
   },
   "source": [
    "Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from synDataFunctionality.TreeLib import Tree, genTree\n",
    "import numpy as np\n",
    "from synDataFunctionality.genInputFromLabel import labelToInput\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "startX = 5\n",
    "startY = 360\n",
    "startAngle = 0\n",
    "starWidth = 15\n",
    "stopWidth = 3\n",
    "startLength = 20\n",
    "bifurcProb = 0.3\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make some trees "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from synDataFunctionality.saveSynData import genSynDat\n",
    "import torch.utils.data as td\n",
    "from DataLoaders import SynData"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make and save some synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [startX, startY, starWidth, startLength, startAngle, stopWidth]\n",
    "num = 9\n",
    "\n",
    "# make num samples\n",
    "genSynDat(\"SynDat/SynInput\", \"SynDat/SynLabel\", lst, (736, 736), num)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test that we can make a dataSet and it outputs data as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 736, 736])\n",
      "torch.Size([1, 736, 736])\n"
     ]
    }
   ],
   "source": [
    "SynDataSet = SynData(\"SynDat/synInput\", \"SynDat/synLabel\")\n",
    "\n",
    "#Test we can retrieve data from Dataset\n",
    "test, lab = SynDataSet[0]\n",
    "print(test.shape)\n",
    "print(lab.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize synthetic generated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#test that dataloader works, and show images\\ntest_loader = td.DataLoader(SynDataSet, batch_size=2)\\n\\ntestIter = iter(test_loader)\\nfor i in range(len(testIter)):\\n    imgs, labs = testIter.next()\\n    grid = torchvision.utils.make_grid(imgs) #.numpy()[0] hack to show tensor in plt\\n    plt.imshow(grid.numpy()[0], cmap=\"gray\", vmin=0, vmax=255)\\n    plt.show()\\n    lab_grid = torchvision.utils.make_grid(labs)\\n    plt.imshow(lab_grid.numpy()[0], cmap=\"gray\", vmin=0, vmax=1)\\n    plt.show()'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchvision\n",
    "\"\"\"\n",
    "#test that dataloader works, and show images\n",
    "test_loader = td.DataLoader(SynDataSet, batch_size=2)\n",
    "\n",
    "testIter = iter(test_loader)\n",
    "for i in range(len(testIter)):\n",
    "    imgs, labs = testIter.next()\n",
    "    grid = torchvision.utils.make_grid(imgs) #.numpy()[0] hack to show tensor in plt\n",
    "    plt.imshow(grid.numpy()[0], cmap=\"gray\", vmin=0, vmax=255)\n",
    "    plt.show()\n",
    "    lab_grid = torchvision.utils.make_grid(labs)\n",
    "    plt.imshow(lab_grid.numpy()[0], cmap=\"gray\", vmin=0, vmax=1)\n",
    "    plt.show()\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that transformations can be applied to dataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test transformations work correctly on dataloader:\n",
    "from torchvision.transforms import RandomVerticalFlip, RandomHorizontalFlip, ColorJitter, CenterCrop, Normalize\n",
    "from torchvision.transforms.functional import rotate\n",
    "import torchvision\n",
    "\n",
    "t_both = [RandomHorizontalFlip(p=0.5),  RandomVerticalFlip(p=0.5)]\n",
    "#Maybe normalize imgs automatically in dataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "TransDataSet = SynData(\"SynDat/synInput\", \"SynDat/synLabel\", transforms_both=t_both)#, transforms_train=t_dat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#test that dataloader works, and show images\\ntrans_loader = td.DataLoader(TransDataSet, batch_size=2)\\n\\ntransIter = iter(trans_loader)\\nfor i in range(len(transIter)):\\n    imgs, labs = transIter.next()\\n    grid = torchvision.utils.make_grid(imgs).numpy()[0]\\n    #print(np.amax(np.array(imgs)))\\n    #print(np.amin(np.array(imgs)))\\n    plt.imshow(grid+1, cmap=\"gray\", vmin=0, vmax=255)\\n    plt.show()\\n    lab_grid = torchvision.utils.make_grid(labs).numpy()[0]\\n    plt.imshow(lab_grid, cmap=\"gray\", vmin=0, vmax=1)\\n    plt.show()'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchvision\n",
    "import numpy as np\n",
    "\"\"\"\n",
    "#test that dataloader works, and show images\n",
    "trans_loader = td.DataLoader(TransDataSet, batch_size=2)\n",
    "\n",
    "transIter = iter(trans_loader)\n",
    "for i in range(len(transIter)):\n",
    "    imgs, labs = transIter.next()\n",
    "    grid = torchvision.utils.make_grid(imgs).numpy()[0]\n",
    "    #print(np.amax(np.array(imgs)))\n",
    "    #print(np.amin(np.array(imgs)))\n",
    "    plt.imshow(grid+1, cmap=\"gray\", vmin=0, vmax=255)\n",
    "    plt.show()\n",
    "    lab_grid = torchvision.utils.make_grid(labs).numpy()[0]\n",
    "    plt.imshow(lab_grid, cmap=\"gray\", vmin=0, vmax=1)\n",
    "    plt.show()\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment with Basic Unet (to test whether it works)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages and files for Unet and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Unet.UNetBasic import UnetBasic\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.cuda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "#make Unet\n",
    "\n",
    "net1 = UnetBasic()\n",
    "\n",
    "#Try to use cuda machine\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#check which device we are on\n",
    "\n",
    "print(device)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make training and testing images. Apply random transformations to them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#note, we comment our genSynDat, as otherwise we kill previous generated data.\n",
    "\n",
    "#Make 300 samples for training data:\n",
    "#genSynDat(\"SynDat/SynInput\", \"SynDat/SynLabel\", lst, (736, 736), 300)\n",
    "trainingData = SynData(\"SynDat/SynInputTrain\", \"SynDat/SynLabelTrain\", t_both)\n",
    "#Make 50 samples as test data:\n",
    "#genSynDat(\"SynDat/SynInputTest\", \"SynDat/SynLabelTest\", lst, (736, 736), 50)\n",
    "testData = SynData(\"SynDat/SynInputTest\", \"SynDat/SynLabelTest\", t_both)\n",
    "\n",
    "trainLoader = td.DataLoader(trainingData, shuffle=True)\n",
    "testLoader = td.DataLoader(testData, shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training our basic Unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,     5] loss: 0.131\n",
      "[1,    10] loss: 0.115\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-9d2d229cf9a5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m#Training, pray for me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mtrainLoss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestLoss\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mnet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainLoop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainLoader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestLoader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint_interv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\nugni\\OneDrive\\Skrivebord\\Bachelor\\git\\Bachelor_rep_angiograms\\src\\trainingFunctionality.py\u001b[0m in \u001b[0;36mtrainLoop\u001b[1;34m(net, optimizer, criterion, device, epochs, train_loader, test_loader, print_interv)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#.float() should fix int error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\nugni\\anaconda3\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 307\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\nugni\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    152\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 154\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from trainingFunctionality import trainLoop\n",
    "\n",
    "net1.to(device) #For now is cpu, but will hopefully be CUDA later\n",
    "net1 = net1.float() #hack that should remove float error\n",
    "\n",
    "#Adam for now\n",
    "optimizer = optim.Adam(net1.parameters(), lr=0.001)\n",
    "criterion = nn.BCELoss()\n",
    "criterion.to(device)\n",
    "\n",
    "#Training, pray for me\n",
    "trainLoss, testLoss , net = trainLoop(net1, optimizer, criterion, device, 2, trainLoader, testLoader, print_interv=5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kill all files created in this session, such to diminish clutter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kill generated files such that we diminish clutter\n",
    "from synDataFunctionality.saveSynData import order_66\n",
    "\n",
    "#order_66(\"SynDat/synInputTrain\", \"SynDat/synLabelTrain\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "dfa4efc2e7985e6916682396d3eaefec524ac10635f8db4811019e26e0d754ec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
